\section{Background and Related Work}
\label{sec:related_work}

A key challenge in motion planning for autonomous robots is efficiency. High-speed planning enables continuous replanning, allowing robots to adapt to unstructured environments. Designing more efficient algorithms and leveraging hardware acceleration are two orthogonal but complementary directions for achieving real-time motion planning. While there has been significant progress in developing faster algorithms~\cite{kuffner2000rrt, sucan2011sampling, otte2016rrtx, gammell2020batch}, our work focuses on hardware acceleration and leverages GPUs to exploit parallelism in classical motion planners such as PRM~\cite{kavraki2002probabilistic}.

Motion planners should also maintain awareness about the context in which they are planning. Rather than merely planning a trajectory, the planner has to consider contextual information. For instance, designing planners that are human-aware or perception aware is critical for enabling autonomous robots to operate effectively in dynamic and unstructured settings.

\subsection{Parallelism and Hardware Acceleration}\label{sec:hardware}

Early efforts on parallel SBMP algorithms were initially discussed in~\cite{henrich1997fast}. Parallelism in SBMP can be applied at different levels and for different purposes. For example, Parallel PRM~\cite{amato1999probabilistic} exploited parallelism for vertex generation and k-nearest-neighbor connections.~\cite{wedge2008heavy} improved average-case performance by running multiple planners in parallel, while~\cite{plaku2005sampling} constructed a forest of tree-based planners in parallel. More recently, VAMP~\cite{thomason2024motions} parallelized collision checking and incorporated early termination strategies to dramatically speed up planning. A parallel RRT* was also proposed in~\cite{xiao2017parallel}. Those works~\cite{amato1999probabilistic, wedge2008heavy, plaku2005sampling} are platform-independent, either due to their generalizability or because GPUs were not yet widely available when the algorithms were introduced.

% Beyond SBMP, parallelism has been widely applied in model predictive control~\cite{bhardwaj2022storm, hyatt2020parameterized} and trajectory optimization~\cite{sundaralingam2023curobo}.

CPUs and GPUs are the two primary hardware platforms for parallelism. CPUs typically rely on single instruction, multiple data
(SIMD) parallelism to accelerate vectorized operations, while GPUs employ single instruction, multiple threads (SIMT) to execute massive numbers of lightweight threads in parallel. CAPT~\cite{ramsey2024collision} is a representative work that leverages SIMD primarily to avoid costly data transfers between CPUs and GPUs. This design choice enables planning for high-DoF robots in highly cluttered and dynamic environments. Subsequent works~\cite{wilson2025nearest, wilson2025aorrtc} adopt SIMD for similar reasons. In contrast, many other approaches~\cite{huang2025prrtc, hu2025cprrtc, sundaralingam2023curobo} utilize SIMT parallelism, taking advantage of the vast number of GPU threads to efficiently compute projections, signed distance fields, and related operations.

The GPU is a natural choice for our work because of PRM's inherent parallelism and our use of neural cost functions. Apart from the initial transfer of sensor data to the GPU and the final transfer of the roadmap back to the CPU, all computations are performed on the GPU, keeping data transfer costs minimal.

\subsection{Context-Aware Motion Planning}
Beyond basic collision avoidance, motion planners often need to account for the specific context and task in which they are deployed. This context-aware motion planning is crucial, as different contexts impose different requirements and constraints, especially in HRI or HRC. In such settings, the robot must not only plan smooth collision-free paths but also take into account human intentions, safety, privacy, and many other factors. For example, in human-aware motion planning~\cite{mainprice2011planning, rajendran2021human}, the most common constraints are visibility and distance. Visibility constraints ensure that the robot remains within the human’s field of view for as long as possible to avoid surprise, while distance constraints maintain a safe separation between the robot and the human. In privacy-aware motion planning~\cite{luo2020privacy, shome2023robots, martin2016privacy}, an additional constraint is introduced: the robot must avoid entering certain areas due to privacy restrictions, or ensure that its camera does not capture the human’s face. In intention-aware motion planning~\cite{park2019planner, ren2022human, liu2024intention, chen2025int2planner}, a common constraint is to incorporate predictions of human intention (often obtained from neural networks~\cite{park2019planner, liu2024intention}) to plan trajectories that either avoid the human or enable effective collaboration.

Another important class of context-aware motion planning is perception-aware motion planning. In perception-aware motion planning, the main objective is for the robot to plan a path such that the viewpoints from its onboard camera are optimized for a given perception task such as 3D scene reconstruction~\cite{zhao2022perception}, object tracking~\cite{falanga2018pampc, tordesillas2023deep}, object pose estimation~\cite{hu2022view}, or object monitoring~\cite{meng2025look}. To achieve this, perception-aware planners typically define a cost function—often derived from neural networks—associated with the robot or camera pose; the planner jointly optimizes both motion cost and perception cost. For instance,~\cite{meng2025look} incorporates estimates of object monitoring performance from a neural surrogate model into the planning process, while~\cite{hu2022view} leverages 6D object poses predicted by a pose estimation network to guide planning.

For most of the context-aware motion planners discussed above, the primary constraint or objective for a given context can be formulated as a cost function defined over the robot configurations and other context-specific variables—for example, the object pose in perception-aware motion planning~\cite{meng2025look,falanga2018pampc} or human intention in human-aware motion planning~\cite{park2019planner}. Moreover, many of these cost functions can be represented by, or directly implemented as, neural networks~\cite{meng2025look, park2019planner, hu2022view, zhao2022perception, chen2025int2planner, martin2016privacy}, which naturally benefit from GPU-based hardware acceleration. This observation demonstrates the need for a GPU-accelerated variant of PRM that achieves real-time performance and generates paths optimized under a neural cost function. 

% Beyond high-performance, real-time planners must also accommodate a wide range of constraints, since field environments are frequently messy and unpredictable. Accordingly, there is a large body of real-time planning research that addresses requirements beyond basic collision avoidance. For example, ~\cite{liu2023task} incorporate the uncertainty of human motion into the planning process, while ~\cite{sisbot2012human} account for human kinematics, preferences, and field-of-view (FOV) to enable safe human-robot collaboration (HRC). ~\cite{xi2024lightweight} develop a highly-efficient reinforcement learning algorithm designed to satisfy strict power consumption constraints for unmanned aerial vehicles (UAVs). ~\cite{papachristos2019localization} and ~\cite{bartolomei2020perception} use trajectory optimization and segmentation maps, respectively, to reduce localization uncertainty for UAVs. CuRobo ~\cite{sundaralingam2023curobo}, an optimization-based planner that allows for constrained planning with locked joints, and cpRRTC ~\cite{hu2025cprrtc}, a derivative of RRT-Connect ~\cite{kuffner2000rrt} that enables end-effector constrained planning, are two state-of-the-art constrained planners that are parallelized for use on GPUs. While these frameworks are capable of replanning on-the-fly while also incorporating specialized constraints, each is tailored specifically for its target application and is not designed to accommodate a broad set of user-defined cost functions.


% This motivates the need to combine real-time general-purpose planning frameworks with the ability to handle a wide array of constraints. Sampling-based planners, such as the probabilistic roadmap (PRM) and rapidly-exploring random tree (RRT) connect, introduced by ~\cite{kavraki2002probabilistic} and ~\cite{kuffner2000rrt}, respectively, can be extensively parallelized ~\cite{amato1999probabilistic,huang2025prrtc} and do not require complex training procedures. At the same time, learning-based planning methods have the potential to quantify abstract environmental qualities that can be used to satisfy novel or non-traditional constraints ~\cite{you2025human, saha2024edmp, sisbot2012human}. Since PRM and related sampling-based planners are already well-suited for handling traditional planning restrictions (e.g., collision avoidance or joint limits), a real-time planning framework that fuses the strengths of learned and traditional objectives, while also supporting user-defined custom cost functions, is highly desirable. 

% \begin{enumerate}
%     \item Perception-aware planning: We sometimes want the robot not only to move to a certain configuration but also to continuously monitor an object from a specific angle while moving. The perception score, which measures the robot's ability to detect objects or humans along a path, can be approximated by a neural network. 
%     \item Human distance aware planning~\cite{mainprice2011planning, rajendran2021human}: In real-world scenarios, a robot must maintain a certain distance from humans. This is crucial for safety in human-robot collaboration. The framework can incorporate this by using a cost function that penalizes configurations where the robot is too close to a human.
%     \item Privacy-aware planning: When humans are present, we might want the robot to avoid looking at their faces to protect their privacy. Such a constraint can be quantified by a neural network and integrated into the planning process.
%     \item Integrating with LLMs or VLMs: Humans can describe their requirements or constraints using natural language. These descriptions can be interpreted by Large Language Models (LLMs) or Vision-Language Models (VLMs), which could then be used to rate the cost of each node, allowing the planner to adapt to a wide range of user-defined constraints.
% \end{enumerate}


% Historically, researchers have developed a number of methods for achieving real-time planning frequencies, such as anytime planning strategies ~\cite{vannoy2008real, van2006anytime}, closed-loop implementations of kinodynamic planners ~\cite{frazzoli2002real, kuwata2009real}, and decomposition of the planning process into manageable subproblems ~\cite{brock2001decomposition}. In this work, we focus on hardware acceleration, a method of reducing planning times that has been employed since the early 1990s and the era of grid-based planners ~\cite{lengyel1990real, lozano1991parallel}.

% There are several types of hardware acceleration techniques. Multithreading on multi-core central, graphics, and tensor processing units (CPU, GPU, and TPUs) enables the execution of single-instruction multiple-thread (SIMT) program architectures, which run one instruction (e.g., “sample a random configuration”) across many concurrent threads. Single-instruction multiple-data (SIMD) techniques allow programmers to apply the same instruction to large arrays of data simultaneously within a single thread. 
% Field-programmable gate arrays (FPGAs) and the creation of custom micro-architectures are two additional hardware techniques commonly used to improve program execution.


% These approaches- SIMD, SIMT, FPGA, and custom micro-architectures- havqe all been successfully used to accelerate motion planning in ~\cite{thomason2024motions, ramsey2024collision, wilson2025nearest}, ~\cite{sundaralingam2023curobo, lee2024gpu, park2013real, pan2012gpu}, ~\cite{atay2006motion, murray2016microarchitecture}, and ~\cite{huang2022hardware}, respectively, often by one or more orders of magnitude. Hardware acceleration is a broadly applicable method of improving planning efficiency; it has been applied to grid-based planning ~\cite{lengyel1990real, lozano1991parallel}, sampling-based planning ~\cite{thomason2024motions, huang2025prrtc}, and optimization-based planning ~\cite{sundaralingam2023curobo, lee2024gpu, park2013real}. Learning-based planners, similarly, are typically reliant on GPU/TPU hardware during training and, to a lesser extent, during deployment ~\cite{ichnowski2020deep}.
